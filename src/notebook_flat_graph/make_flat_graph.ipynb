{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Redo graph.pkl",
   "id": "30b101bff87aff3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T19:46:58.172455Z",
     "start_time": "2025-09-08T19:46:40.232334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "from gc import garbage\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from src.inspector_git import IGLogReader, GitLogDTO\n",
    "from src.jira_miner.models import JsonFileFormatJira\n",
    "from src.github_miner import JsonFileFormatGithub\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from flat_graph import *\n",
    "\n",
    "# JSON\n",
    "path_jira = \"../../test-input/jira-miner/ZEPPELIN-detailed-issues.json\"\n",
    "path_github = \"../../test-input/github-miner/githubProject.json\"\n",
    "# IGLOG\n",
    "path_inspector_git = \"../../test-input/inspector-git/zeppelin.iglog\"\n",
    "\n",
    "\n",
    "\n",
    "def load_from_json(model_cls, file_path: str):\n",
    "    \"\"\"Load JSON from a given path and validate it with the provided model class.\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return model_cls.model_validate(data)\n",
    "\n",
    "def load_jsons():\n",
    "    jira_data_loaded = load_from_json(JsonFileFormatJira, path_jira)\n",
    "    github_data_loaded = load_from_json(JsonFileFormatGithub, path_github)\n",
    "    return jira_data_loaded, github_data_loaded\n",
    "\n",
    "ig_log_reader = IGLogReader()\n",
    "\n",
    "\n",
    "\n",
    "jira_data, github_data = load_jsons()\n",
    "inspector_git_data = ig_log_reader.read(path_inspector_git)\n",
    "graph = Graph()"
   ],
   "id": "b54506f12daf190b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x735167b22ea0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vortex/.conda/envs/Vortex/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T15:35:56.419288Z",
     "start_time": "2025-09-08T15:35:55.585335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import flat_graph  # <-- matches the filename flat_graph.py\n",
    "importlib.reload(flat_graph)\n",
    "\n",
    "from flat_graph import Graph  # or whatever you need\n",
    "\n",
    "\n",
    "graph.add_inspector_git_data(inspector_git_data)\n"
   ],
   "id": "1e6c8422522ec100",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T15:35:59.567870Z",
     "start_time": "2025-09-08T15:35:59.564912Z"
    }
   },
   "cell_type": "code",
   "source": "print(graph.summary())",
   "id": "7553a3dad9132c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Graph summary ~~~~\n",
      "commits: 5512\n",
      "git_users: 602\n",
      "files: 2448\n",
      "\n",
      "issue_statuses: 0\n",
      "issue_types: 0\n",
      "issue_status_categories: 0\n",
      "jira_users: 0\n",
      "issues: 0\n",
      "\n",
      "pull_requests: 0\n",
      "git_hub_users: 0\n",
      "git_hub_commits: 0\n",
      "\n",
      "nodes: 8562\n",
      "edges: 66499\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T15:36:19.444791Z",
     "start_time": "2025-09-08T15:36:19.440049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fisiere = [f.path for f in graph.files.values()]\n",
    "strings_sorted = sorted(fisiere)\n",
    "# Save to file\n",
    "with open(\"flat.txt\", \"w\") as f:\n",
    "    for item in strings_sorted:\n",
    "        f.write(item + \"\\n\")"
   ],
   "id": "a1826cd8107ae18c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T11:30:36.547276Z",
     "start_time": "2025-09-08T11:30:17.024296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_jira_data(graph:Graph, jira_data: JsonFileFormatJira):\n",
    "    def add_issue_statuses():\n",
    "        for status in jira_data.issueStatuses:\n",
    "            category = IssueStatusCategory(\n",
    "                key=status.statusCategory.key,\n",
    "                name=status.statusCategory.name\n",
    "            )\n",
    "            status = IssueStatus(\n",
    "                id=status.id,\n",
    "                name=status.name,\n",
    "            )\n",
    "\n",
    "            graph.add_issue_status_category(category)\n",
    "            graph.add_issue_status(status)\n",
    "\n",
    "            edge = IssueStatusIssueStatusCategoryEdge(\n",
    "                issue_status=status,\n",
    "                issue_status_category=category,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "    def add_issue_types():\n",
    "        for issue_type in jira_data.issueTypes:\n",
    "            issue_type = IssueType(\n",
    "                id=issue_type.id,\n",
    "                name=issue_type.name,\n",
    "                description=issue_type.description,\n",
    "                isSubTask=issue_type.isSubTask,\n",
    "            )\n",
    "            graph.add_issue_type(issue_type)\n",
    "\n",
    "    def add_users():\n",
    "        for user in jira_data.users:\n",
    "            jira_user = JiraUser(\n",
    "                key=user.key,\n",
    "                name=user.name,\n",
    "                link=user.self_,\n",
    "            )\n",
    "            graph.add_jira_user(jira_user)\n",
    "\n",
    "    def add_issues():\n",
    "        for issue in jira_data.issues:\n",
    "            i = Issue(\n",
    "                id=issue.id,\n",
    "                key=issue.key,\n",
    "                summary=issue.summary,\n",
    "                createdAt=issue.created,\n",
    "                updatedAt=issue.updated,\n",
    "            )\n",
    "            graph.add_issue(i)\n",
    "\n",
    "            issue_status = graph.get_issue_status(issue.status.id)\n",
    "            issue_issue_status_edge = IssueIssueStatusEdge(\n",
    "                issue_status=issue_status,\n",
    "                issue=i\n",
    "            )\n",
    "            graph.add_edge(issue_issue_status_edge)\n",
    "\n",
    "            issue_type = graph.get_issue_type(issue.issueType)\n",
    "            issue_issue_type_edge = IssueIssueTypeEdge(\n",
    "                issue_type=issue_type,\n",
    "                issue=i\n",
    "            )\n",
    "            graph.add_edge(issue_issue_type_edge)\n",
    "\n",
    "            reporter = graph.get_jira_user(issue.reporterId)\n",
    "            reporter_edge = IssueJiraUserEdge(\n",
    "                jira_user=reporter,\n",
    "                issue=i,\n",
    "                role= \"reporter\"\n",
    "            )\n",
    "            graph.add_edge(reporter_edge)\n",
    "            if issue.creatorId is not None:\n",
    "                creator = graph.get_jira_user(issue.creatorId)\n",
    "                creator_edge = IssueJiraUserEdge(\n",
    "                jira_user=creator,\n",
    "                issue=i,\n",
    "                role= \"creator\"\n",
    "                )\n",
    "                graph.add_edge(creator_edge)\n",
    "\n",
    "            if issue.assigneeId is not None:\n",
    "                assignee = graph.get_jira_user(issue.assigneeId)\n",
    "                assignee_edge = IssueJiraUserEdge(\n",
    "                    jira_user=assignee,\n",
    "                    issue=i,\n",
    "                    role= \"assignee\"\n",
    "                )\n",
    "                graph.add_edge(assignee_edge)\n",
    "\n",
    "    def add_edge_if_absent(graph, edge: IssueIssueEdge):\n",
    "        \"\"\"Add an IssueIssueEdge only if it doesn't already exist.\"\"\"\n",
    "        existing_edges = graph.adjacency.get(edge.child.dict_key(), {}).get(\"issues\", [])\n",
    "        if not any(\n",
    "            isinstance(e, IssueIssueEdge) and e.normalized_key() == edge.normalized_key()\n",
    "            for e in existing_edges\n",
    "        ):\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "    def make_issue_parent_connections():\n",
    "        for jira_issue in jira_data.issues:\n",
    "            current_issue = graph.get_issue(jira_issue.key)\n",
    "\n",
    "            # ðŸ”¹ Connect to parent\n",
    "            if jira_issue.parent is not None:\n",
    "                parent_issue = graph.get_issue(jira_issue.parent)\n",
    "                edge = IssueIssueEdge(child=current_issue, parent=parent_issue)\n",
    "                add_edge_if_absent(graph, edge)\n",
    "\n",
    "            # ðŸ”¹ Connect to subtasks\n",
    "            for subtask_id in jira_issue.subTasks or []:\n",
    "                child_issue = graph.get_issue(subtask_id)\n",
    "                edge = IssueIssueEdge(child=child_issue, parent=current_issue)\n",
    "                add_edge_if_absent(graph, edge)\n",
    "\n",
    "\n",
    "    add_issue_statuses()\n",
    "    add_issue_types()\n",
    "    add_users()\n",
    "    add_issues()\n",
    "    make_issue_parent_connections()\n",
    "\n",
    "add_jira_data(graph, jira_data)\n",
    "\n",
    "def add_github_data(graph:Graph, github_data: JsonFileFormatGithub):\n",
    "    a = 0\n",
    "    cre = 0\n",
    "    m = 0\n",
    "    for pr in github_data.pullRequests:\n",
    "        # ADD PR\n",
    "        pull_request = PullRequest(\n",
    "            number=pr.number,\n",
    "            title=pr.title,\n",
    "            state=pr.state,\n",
    "            changedFiles=pr.changedFiles,\n",
    "            createdAt=pr.createdAt,\n",
    "            updatedAt=pr.updatedAt,\n",
    "            body=pr.body,\n",
    "            mergedAt=pr.mergedAt,\n",
    "            closedAt=pr.closedAt,\n",
    "        )\n",
    "        graph.add_pull_request(pull_request)\n",
    "\n",
    "        # ADD ALL USERS\n",
    "        for assignee in pr.assignees:\n",
    "            assignee_git_hub_user = GitHubUser(\n",
    "                url=assignee.url,\n",
    "                login=assignee.login,\n",
    "                name=assignee.name,\n",
    "            )\n",
    "            graph.add_git_hub_user(assignee_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= assignee_git_hub_user,\n",
    "                role = \"assignee\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            a += 1\n",
    "\n",
    "        if pr.createdBy:\n",
    "            creator_git_hub_user = GitHubUser(\n",
    "                url=pr.createdBy.url,\n",
    "                login=pr.createdBy.login,\n",
    "                name=pr.createdBy.name,\n",
    "            )\n",
    "            graph.add_git_hub_user(creator_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= creator_git_hub_user,\n",
    "                role = \"creator\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            cre += 1\n",
    "\n",
    "        if pr.mergedBy:\n",
    "            merger_git_hub_user = GitHubUser(\n",
    "                name=pr.mergedBy.name,\n",
    "                url=pr.mergedBy.url,\n",
    "                login=pr.mergedBy.login,\n",
    "            )\n",
    "            graph.add_git_hub_user(merger_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= merger_git_hub_user,\n",
    "                role = \"merger\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            m += 1\n",
    "\n",
    "        # ADD ALL COMMITS\n",
    "        for c in pr.commits:\n",
    "            commit = GitHubCommit(\n",
    "                sha=c.sha,\n",
    "                date=c.date,\n",
    "                message=c.message,\n",
    "                changedFiles=c.changedFiles,\n",
    "            )\n",
    "            graph.add_git_hub_commit(commit)\n",
    "\n",
    "            edge = PullRequestGitHubCommitEdge(\n",
    "                commit = commit,\n",
    "                pr = pull_request,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "add_github_data(graph, github_data)\n",
    "\n",
    "def save_pickle(obj, var_name: str, base_dir: str = \"pickle_data\") -> Path:\n",
    "    \"\"\"\n",
    "    Save a Python object using pickle in a directory relative to the notebook.\n",
    "\n",
    "    Args:\n",
    "        obj: The Python object to save.\n",
    "        var_name: Name of the variable (used as filename).\n",
    "        base_dir: Relative directory to save pickles (default: \"pickle_data\").\n",
    "\n",
    "    Returns:\n",
    "        Path to the saved pickle file.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = Path(base_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build full path\n",
    "    pickle_path = save_dir / f\"{var_name}.pkl\"\n",
    "\n",
    "    # Save object\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "    print(f\"Saved {var_name} to {pickle_path}\")\n",
    "    return pickle_path\n",
    "\n",
    "# Save your loaded data\n",
    "save_pickle(graph, \"graph\")\n",
    "print(graph.summary())"
   ],
   "id": "bfe9b65ecef11a51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph to pickle_data/graph.pkl\n",
      "~~~~ Graph summary ~~~~\n",
      "commits: 5512\n",
      "git_users: 602\n",
      "files: 5644\n",
      "\n",
      "issue_statuses: 48\n",
      "issue_types: 7\n",
      "issue_status_categories: 3\n",
      "jira_users: 2008\n",
      "issues: 6202\n",
      "\n",
      "pull_requests: 5022\n",
      "git_hub_users: 690\n",
      "git_hub_commits: 17869\n",
      "\n",
      "nodes: 43607\n",
      "edges: 122314\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Make graph fully connected",
   "id": "6cfcf28d371eb05e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T10:40:31.535662Z",
     "start_time": "2025-09-08T10:40:29.604112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_issues_with_git_commits(graph: Graph):\n",
    "    # Build one regex to match all issue keys\n",
    "    issue_keys = [re.escape(issue.key) for issue in graph.issues.values()]\n",
    "    issue_pattern = re.compile(r'\\b(' + '|'.join(issue_keys) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    links = 0\n",
    "    commits_liked_with_issues = 0\n",
    "    for commit in graph.commits.values():\n",
    "        if not commit.message:\n",
    "            continue\n",
    "\n",
    "        matches = issue_pattern.findall(commit.message)\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            commits_liked_with_issues += 1\n",
    "        for match in set(matches):\n",
    "            issue = graph.get_issue(match.upper())\n",
    "            edge = GitCommitIssueEdge(\n",
    "                git_commit = commit,\n",
    "                issue = issue,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            links += 1\n",
    "\n",
    "    print(f\"There are {links} Issueâ€“Commit edges\")\n",
    "    print(f\"Commits liked with issues: {commits_liked_with_issues}\")\n",
    "\n",
    "def link_pull_request_with_issue(graph: Graph, jira_data: JsonFileFormatJira):\n",
    "    # Build one regex for all issue keys\n",
    "    issue_keys = [re.escape(issue.key) for issue in graph.issues.values()]\n",
    "    issue_pattern = re.compile(r'\\b(' + '|'.join(issue_keys) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    links = 0\n",
    "    prs_with_issues = 0\n",
    "\n",
    "    for pr in graph.pull_requests.values():\n",
    "        text = (pr.title or \"\") + \" \" + (pr.body or \"\")\n",
    "        matches = issue_pattern.findall(text)\n",
    "\n",
    "        if matches:\n",
    "            prs_with_issues += 1\n",
    "        for match in set(matches):\n",
    "            issue = graph.get_issue(match.upper())\n",
    "            if issue:\n",
    "                edge = PullRequestIssueEdge(\n",
    "                    pr=pr,\n",
    "                    issue=issue,\n",
    "                )\n",
    "                graph.add_edge(edge)\n",
    "                links += 1\n",
    "\n",
    "    print(f\"Created {links} PRâ€“Issue edges\")\n",
    "    print(f\"PRs linked with issues: {prs_with_issues}\")\n",
    "\n",
    "    def extract_pr_number(text: str) -> int | None:\n",
    "        match = re.search(r'#(\\d+)', text)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    for issue in jira_data.issues:\n",
    "        issues_pr_links = set()\n",
    "        for change in issue.changes:\n",
    "            for item in change.items:\n",
    "                if item.toString and \"Pull Request #\" in item.toString:\n",
    "                    issues_pr_links.add(item.toString)\n",
    "        if len(issues_pr_links) > 0:\n",
    "            i = graph.get_issue(issue.key)\n",
    "            for link in issues_pr_links:\n",
    "                pr = graph.get_pull_request(extract_pr_number(link))\n",
    "                if not pr:\n",
    "                    print(f\"Unknown reference in {i.key} of a pull request: {link}\")\n",
    "                    continue\n",
    "\n",
    "                edge = PullRequestIssueEdge(\n",
    "                    pr=pr,\n",
    "                    issue=i,\n",
    "                )\n",
    "                graph.add_edge(edge)\n",
    "\n",
    "def link_pull_requests_with_git_commits(graph: Graph, min_similarity = 0.85):\n",
    "    counts = {\n",
    "        \"merged_as\": 0,\n",
    "        \"linked_via_issue\": 0\n",
    "    }\n",
    "    for pr in graph.pull_requests.values():\n",
    "        pr_commits = [c.commit for c in graph.adjacency.get(pr.dict_key(), {}).get(\"git_hub_commits\", [])]\n",
    "\n",
    "        for pr_commit in pr_commits:\n",
    "            # 1. Exact SHA match\n",
    "            if git_commit := graph.commits.get(f\"GitCommit:{pr_commit.sha}\"):\n",
    "                graph.add_edge(GitCommitPullRequestEdge(\n",
    "                    git_commit=git_commit,\n",
    "                    pr=pr,\n",
    "                    relation=\"merged_as\"\n",
    "                ))\n",
    "                counts[\"merged_as\"] += 1\n",
    "\n",
    "        # 2. Issue-based linking (fallback)\n",
    "        issues_linked_to_pr = [\n",
    "            edge.issue for edge in graph.adjacency.get(pr.dict_key(), {}).get(\"issues\", [])\n",
    "        ]\n",
    "        for issue in issues_linked_to_pr:\n",
    "            git_commits_for_issue = [\n",
    "                edge.git_commit for edge in graph.adjacency.get(issue.dict_key(), {}).get(\"git_commits\", [])\n",
    "            ]\n",
    "\n",
    "            existing_edges = set()\n",
    "\n",
    "            for git_commit in git_commits_for_issue:\n",
    "                edge = GitCommitPullRequestEdge(\n",
    "                    git_commit=git_commit,\n",
    "                    pr=pr,\n",
    "                    relation=\"linked_via_issue\"\n",
    "                )\n",
    "                if edge not in existing_edges:\n",
    "                    graph.add_edge(edge)\n",
    "                    counts[\"linked_via_issue\"] += 1\n",
    "                    existing_edges.add(edge)\n",
    "\n",
    "    for key in counts.keys():\n",
    "        print(f\"{key}: {counts[key]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_pickle(obj, var_name: str, base_dir: str = \"pickle_data\") -> Path:\n",
    "    \"\"\"\n",
    "    Save a Python object using pickle in a directory relative to the notebook.\n",
    "\n",
    "    Args:\n",
    "        obj: The Python object to save.\n",
    "        var_name: Name of the variable (used as filename).\n",
    "        base_dir: Relative directory to save pickles (default: \"pickle_data\").\n",
    "\n",
    "    Returns:\n",
    "        Path to the saved pickle file.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = Path(base_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build full path\n",
    "    pickle_path = save_dir / f\"{var_name}.pkl\"\n",
    "\n",
    "    # Save object\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "    print(f\"Saved {var_name} to {pickle_path}\")\n",
    "    return pickle_path\n",
    "\n",
    "\n",
    "\n",
    "link_issues_with_git_commits(graph)\n",
    "link_pull_request_with_issue(graph, jira_data)\n",
    "# 8 min 33 sec\n",
    "link_pull_requests_with_git_commits(graph)\n",
    "\n",
    "save_pickle(graph, \"graph\")\n"
   ],
   "id": "80b21a3fd419e3bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3642 Issueâ€“Commit edges\n",
      "Commits liked with issues: 3209\n",
      "Created 4385 PRâ€“Issue edges\n",
      "PRs linked with issues: 3974\n",
      "Unknown reference in ZEPPELIN-6282 of a pull request: This issue links to \"GitHub Pull Request #5026 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6283 of a pull request: This issue links to \"GitHub Pull Request #5030 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6280 of a pull request: This issue links to \"GitHub Pull Request #5028 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6281 of a pull request: This issue links to \"GitHub Pull Request #5029 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6276 of a pull request: This issue links to \"GitHub Pull Request #5027 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6164 of a pull request: This issue links to \"GitHub Pull Request #5031 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-1326 of a pull request: This issue links to \"GitHub Pull Request # (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-6181 of a pull request: This issue links to \"GitHub Pull Request #5024 (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-2152 of a pull request: This issue links to \"GitHub Pull Request # (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-1179 of a pull request: This issue links to \"GitHub Pull Request # (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-1169 of a pull request: This issue links to \"GitHub Pull Request # (Web Link)\"\n",
      "Unknown reference in ZEPPELIN-3190 of a pull request: This issue links to \"GitHub Pull Request # (Web Link)\"\n",
      "merged_as: 916\n",
      "linked_via_issue: 11837\n",
      "Saved graph to pickle_data/graph.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('pickle_data/graph.pkl')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Altele",
   "id": "350d307d51eac43c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a33c55f2815049b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
