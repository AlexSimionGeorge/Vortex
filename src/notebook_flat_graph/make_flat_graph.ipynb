{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Redo graph.pkl",
   "id": "30b101bff87aff3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T23:00:49.238032Z",
     "start_time": "2025-09-07T23:00:28.968286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from src.inspector_git import IGLogReader, GitLogDTO\n",
    "from src.jira_miner.models import JsonFileFormatJira\n",
    "from src.github_miner import JsonFileFormatGithub\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from flat_graph import *\n",
    "\n",
    "# JSON\n",
    "path_jira = \"/home/vortex/Work/BachelorThesis/test_vartex/Vortex/test-input/jira-miner/ZEPPELIN-detailed-issues.json\"\n",
    "path_github = \"/home/vortex/Work/BachelorThesis/test_vartex/Vortex/test-input/github-miner/githubProject.json\"\n",
    "# IGLOG\n",
    "path_inspector_git = \"/home/vortex/Work/BachelorThesis/test_vartex/Vortex/test-input/inspector-git/zeppelin.iglog\"\n",
    "\n",
    "\n",
    "\n",
    "def load_from_json(model_cls, file_path: str):\n",
    "    \"\"\"Load JSON from a given path and validate it with the provided model class.\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return model_cls.model_validate(data)\n",
    "\n",
    "def load_jsons():\n",
    "    jira_data_loaded = load_from_json(JsonFileFormatJira, path_jira)\n",
    "    github_data_loaded = load_from_json(JsonFileFormatGithub, path_github)\n",
    "    return jira_data_loaded, github_data_loaded\n",
    "\n",
    "IGLogReader = IGLogReader()\n",
    "\n",
    "\n",
    "\n",
    "jira_data, github_data = load_jsons()\n",
    "inspector_git_data = IGLogReader.read(path_inspector_git)\n",
    "graph = Graph()\n",
    "\n",
    "def add_inspector_git_data(graph:Graph, inspector_git_data: GitLogDTO):\n",
    "    git_date_format = \"%a %b %d %H:%M:%S %Y %z\"\n",
    "\n",
    "    for commitDTO in inspector_git_data.commits:\n",
    "        commit = GitCommit(\n",
    "            sha=commitDTO.id,\n",
    "            message=commitDTO.message,\n",
    "            author_date=datetime.strptime(commitDTO.author_date, git_date_format),\n",
    "            committer_date=datetime.strptime(commitDTO.committer_date, git_date_format)\n",
    "        )\n",
    "        graph.add_commit(commit)\n",
    "\n",
    "        author = GitUser(email=commitDTO.author_email, name=commitDTO.author_name)\n",
    "        committer = GitUser(email=commitDTO.committer_email, name=commitDTO.committer_name)\n",
    "        graph.add_user_git(author)\n",
    "        graph.add_user_git(committer)\n",
    "\n",
    "        author_edge = GitCommitGitUserEdge(commit=commit, git_user=author, role=\"author\")\n",
    "        committer_edge = GitCommitGitUserEdge(commit=commit, git_user=committer, role=\"committer\")\n",
    "        graph.add_edge(author_edge)\n",
    "        graph.add_edge(committer_edge)\n",
    "\n",
    "        for change in commitDTO.changes:\n",
    "            file = File(path = change.new_file_name)\n",
    "            graph.add_file(file = file , old_name = change.old_file_name)\n",
    "\n",
    "            file_commit_edge = GitCommitFileEdge(commit=commit, file=file)\n",
    "            file_writer_edge = GitUserFileEdge(git_user=committer, file=file, role=\"writer\")\n",
    "            graph.add_edge(file_commit_edge)\n",
    "            graph.add_edge(file_writer_edge)\n",
    "\n",
    "            if author.email != committer.email:\n",
    "                file_reviewer_edge = GitUserFileEdge(git_user=author, file=file, role=\"reviewer\")\n",
    "                graph.add_edge(file_reviewer_edge)\n",
    "\n",
    "add_inspector_git_data(graph, inspector_git_data)\n",
    "\n",
    "def add_jira_data(graph:Graph, jira_data: JsonFileFormatJira):\n",
    "    def add_issue_statuses():\n",
    "        for status in jira_data.issueStatuses:\n",
    "            category = IssueStatusCategory(\n",
    "                key=status.statusCategory.key,\n",
    "                name=status.statusCategory.name\n",
    "            )\n",
    "            status = IssueStatus(\n",
    "                id=status.id,\n",
    "                name=status.name,\n",
    "            )\n",
    "\n",
    "            graph.add_issue_status_category(category)\n",
    "            graph.add_issue_status(status)\n",
    "\n",
    "            edge = IssueStatusIssueStatusCategoryEdge(\n",
    "                issue_status=status,\n",
    "                issue_status_category=category,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "    def add_issue_types():\n",
    "        for issue_type in jira_data.issueTypes:\n",
    "            issue_type = IssueType(\n",
    "                id=issue_type.id,\n",
    "                name=issue_type.name,\n",
    "                description=issue_type.description,\n",
    "                isSubTask=issue_type.isSubTask,\n",
    "            )\n",
    "            graph.add_issue_type(issue_type)\n",
    "\n",
    "    def add_users():\n",
    "        for user in jira_data.users:\n",
    "            jira_user = JiraUser(\n",
    "                key=user.key,\n",
    "                name=user.name,\n",
    "                link=user.self_,\n",
    "            )\n",
    "            graph.add_jira_user(jira_user)\n",
    "\n",
    "    def add_issues():\n",
    "        for issue in jira_data.issues:\n",
    "            i = Issue(\n",
    "                id=issue.id,\n",
    "                key=issue.key,\n",
    "                summary=issue.summary,\n",
    "                createdAt=issue.created,\n",
    "                updatedAt=issue.updated,\n",
    "            )\n",
    "            graph.add_issue(i)\n",
    "\n",
    "            issue_status = graph.get_issue_status(issue.status.id)\n",
    "            issue_issue_status_edge = IssueIssueStatusEdge(\n",
    "                issue_status=issue_status,\n",
    "                issue=i\n",
    "            )\n",
    "            graph.add_edge(issue_issue_status_edge)\n",
    "\n",
    "            issue_type = graph.get_issue_type(issue.issueType)\n",
    "            issue_issue_type_edge = IssueIssueTypeEdge(\n",
    "                issue_type=issue_type,\n",
    "                issue=i\n",
    "            )\n",
    "            graph.add_edge(issue_issue_type_edge)\n",
    "\n",
    "            reporter = graph.get_jira_user(issue.reporterId)\n",
    "            reporter_edge = IssueJiraUserEdge(\n",
    "                jira_user=reporter,\n",
    "                issue=i,\n",
    "                role= \"reporter\"\n",
    "            )\n",
    "            graph.add_edge(reporter_edge)\n",
    "            if issue.creatorId is not None:\n",
    "                creator = graph.get_jira_user(issue.creatorId)\n",
    "                creator_edge = IssueJiraUserEdge(\n",
    "                jira_user=creator,\n",
    "                issue=i,\n",
    "                role= \"creator\"\n",
    "                )\n",
    "                graph.add_edge(creator_edge)\n",
    "\n",
    "            if issue.assigneeId is not None:\n",
    "                assignee = graph.get_jira_user(issue.assigneeId)\n",
    "                assignee_edge = IssueJiraUserEdge(\n",
    "                    jira_user=assignee,\n",
    "                    issue=i,\n",
    "                    role= \"assignee\"\n",
    "                )\n",
    "                graph.add_edge(assignee_edge)\n",
    "\n",
    "    def add_edge_if_absent(graph, edge: IssueIssueEdge):\n",
    "        \"\"\"Add an IssueIssueEdge only if it doesn't already exist.\"\"\"\n",
    "        existing_edges = graph.adjacency.get(edge.child.dict_key(), {}).get(\"issues\", [])\n",
    "        if not any(\n",
    "            isinstance(e, IssueIssueEdge) and e.normalized_key() == edge.normalized_key()\n",
    "            for e in existing_edges\n",
    "        ):\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "    def make_issue_parent_connections():\n",
    "        for jira_issue in jira_data.issues:\n",
    "            current_issue = graph.get_issue(jira_issue.key)\n",
    "\n",
    "            # ðŸ”¹ Connect to parent\n",
    "            if jira_issue.parent is not None:\n",
    "                parent_issue = graph.get_issue(jira_issue.parent)\n",
    "                edge = IssueIssueEdge(child=current_issue, parent=parent_issue)\n",
    "                add_edge_if_absent(graph, edge)\n",
    "\n",
    "            # ðŸ”¹ Connect to subtasks\n",
    "            for subtask_id in jira_issue.subTasks or []:\n",
    "                child_issue = graph.get_issue(subtask_id)\n",
    "                edge = IssueIssueEdge(child=child_issue, parent=current_issue)\n",
    "                add_edge_if_absent(graph, edge)\n",
    "\n",
    "\n",
    "    add_issue_statuses()\n",
    "    add_issue_types()\n",
    "    add_users()\n",
    "    add_issues()\n",
    "    make_issue_parent_connections()\n",
    "\n",
    "add_jira_data(graph, jira_data)\n",
    "\n",
    "def add_github_data(graph:Graph, github_data: JsonFileFormatGithub):\n",
    "    a = 0\n",
    "    cre = 0\n",
    "    m = 0\n",
    "    for pr in github_data.pullRequests:\n",
    "        # ADD PR\n",
    "        pull_request = PullRequest(\n",
    "            number=pr.number,\n",
    "            title=pr.title,\n",
    "            state=pr.state,\n",
    "            changedFiles=pr.changedFiles,\n",
    "            createdAt=pr.createdAt,\n",
    "            updatedAt=pr.updatedAt,\n",
    "            body=pr.body,\n",
    "            mergedAt=pr.mergedAt,\n",
    "            closedAt=pr.closedAt,\n",
    "        )\n",
    "        graph.add_pull_request(pull_request)\n",
    "\n",
    "        # ADD ALL USERS\n",
    "        for assignee in pr.assignees:\n",
    "            assignee_git_hub_user = GitHubUser(\n",
    "                url=assignee.url,\n",
    "                login=assignee.login,\n",
    "                name=assignee.name,\n",
    "            )\n",
    "            graph.add_git_hub_user(assignee_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= assignee_git_hub_user,\n",
    "                role = \"assignee\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            a += 1\n",
    "\n",
    "        if pr.createdBy:\n",
    "            creator_git_hub_user = GitHubUser(\n",
    "                url=pr.createdBy.url,\n",
    "                login=pr.createdBy.login,\n",
    "                name=pr.createdBy.name,\n",
    "            )\n",
    "            graph.add_git_hub_user(creator_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= creator_git_hub_user,\n",
    "                role = \"creator\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            cre += 1\n",
    "\n",
    "        if pr.mergedBy:\n",
    "            merger_git_hub_user = GitHubUser(\n",
    "                name=pr.mergedBy.name,\n",
    "                url=pr.mergedBy.url,\n",
    "                login=pr.mergedBy.login,\n",
    "            )\n",
    "            graph.add_git_hub_user(merger_git_hub_user)\n",
    "\n",
    "            edge = PullRequestGitHubUserEdge(\n",
    "                pr = pull_request,\n",
    "                git_hub_user= merger_git_hub_user,\n",
    "                role = \"merger\"\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            m += 1\n",
    "\n",
    "        # ADD ALL COMMITS\n",
    "        for c in pr.commits:\n",
    "            commit = GitHubCommit(\n",
    "                sha=c.sha,\n",
    "                date=c.date,\n",
    "                message=c.message,\n",
    "                changedFiles=c.changedFiles,\n",
    "            )\n",
    "            graph.add_git_hub_commit(commit)\n",
    "\n",
    "            edge = PullRequestGitHubCommitEdge(\n",
    "                commit = commit,\n",
    "                pr = pull_request,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "\n",
    "add_github_data(graph, github_data)\n",
    "\n",
    "def save_pickle(obj, var_name: str, base_dir: str = \"pickle_data\") -> Path:\n",
    "    \"\"\"\n",
    "    Save a Python object using pickle in a directory relative to the notebook.\n",
    "\n",
    "    Args:\n",
    "        obj: The Python object to save.\n",
    "        var_name: Name of the variable (used as filename).\n",
    "        base_dir: Relative directory to save pickles (default: \"pickle_data\").\n",
    "\n",
    "    Returns:\n",
    "        Path to the saved pickle file.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = Path(base_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build full path\n",
    "    pickle_path = save_dir / f\"{var_name}.pkl\"\n",
    "\n",
    "    # Save object\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "    print(f\"Saved {var_name} to {pickle_path}\")\n",
    "    return pickle_path\n",
    "\n",
    "# Save your loaded data\n",
    "save_pickle(graph, \"graph\")"
   ],
   "id": "bfe9b65ecef11a51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph to pickle_data/graph.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('pickle_data/graph.pkl')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Make graph fully connected",
   "id": "6cfcf28d371eb05e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T23:00:51.080741Z",
     "start_time": "2025-09-07T23:00:49.245388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_issues_with_git_commits(graph: Graph):\n",
    "    # Build one regex to match all issue keys\n",
    "    issue_keys = [re.escape(issue.key) for issue in graph.issues.values()]\n",
    "    issue_pattern = re.compile(r'\\b(' + '|'.join(issue_keys) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    links = 0\n",
    "    commits_liked_with_issues = 0\n",
    "    for commit in graph.commits.values():\n",
    "        if not commit.message:\n",
    "            continue\n",
    "\n",
    "        matches = issue_pattern.findall(commit.message)\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            commits_liked_with_issues += 1\n",
    "        for match in set(matches):\n",
    "            issue = graph.get_issue(match.upper())\n",
    "            edge = GitCommitIssueEdge(\n",
    "                git_commit = commit,\n",
    "                issue = issue,\n",
    "            )\n",
    "            graph.add_edge(edge)\n",
    "            links += 1\n",
    "\n",
    "    print(f\"There are {links} Issueâ€“Commit edges\")\n",
    "    print(f\"Commits liked with issues: {commits_liked_with_issues}\")\n",
    "\n",
    "def link_pull_request_with_issue(graph: Graph):\n",
    "    # Build one regex for all issue keys\n",
    "    issue_keys = [re.escape(issue.key) for issue in graph.issues.values()]\n",
    "    issue_pattern = re.compile(r'\\b(' + '|'.join(issue_keys) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    links = 0\n",
    "    prs_with_issues = 0\n",
    "\n",
    "    for pr in graph.pull_requests.values():\n",
    "        text = (pr.title or \"\") + \" \" + (pr.body or \"\")\n",
    "        matches = issue_pattern.findall(text)\n",
    "\n",
    "        if matches:\n",
    "            prs_with_issues += 1\n",
    "        for match in set(matches):\n",
    "            issue = graph.get_issue(match.upper())\n",
    "            if issue:\n",
    "                edge = PullRequestIssueEdge(\n",
    "                    pr=pr,\n",
    "                    issue=issue,\n",
    "                )\n",
    "                graph.add_edge(edge)\n",
    "                links += 1\n",
    "\n",
    "    print(f\"Created {links} PRâ€“Issue edges\")\n",
    "    print(f\"PRs linked with issues: {prs_with_issues}\")\n",
    "\n",
    "def link_pull_requests_with_git_commits(graph: Graph, min_similarity = 0.85):\n",
    "    counts = {\n",
    "        \"merged_as\": 0,\n",
    "        \"linked_via_issue\": 0\n",
    "    }\n",
    "    for pr in graph.pull_requests.values():\n",
    "        pr_commits = [c.commit for c in graph.adjacency.get(pr.dict_key(), {}).get(\"git_hub_commits\", [])]\n",
    "\n",
    "        for pr_commit in pr_commits:\n",
    "            # 1. Exact SHA match\n",
    "            if git_commit := graph.commits.get(f\"GitCommit:{pr_commit.sha}\"):\n",
    "                graph.add_edge(GitCommitPullRequestEdge(\n",
    "                    git_commit=git_commit,\n",
    "                    pr=pr,\n",
    "                    relation=\"merged_as\"\n",
    "                ))\n",
    "                counts[\"merged_as\"] += 1\n",
    "\n",
    "        # 2. Issue-based linking (fallback)\n",
    "        issues_linked_to_pr = [\n",
    "            edge.issue for edge in graph.adjacency.get(pr.dict_key(), {}).get(\"issues\", [])\n",
    "        ]\n",
    "        for issue in issues_linked_to_pr:\n",
    "            git_commits_for_issue = [\n",
    "                edge.git_commit for edge in graph.adjacency.get(issue.dict_key(), {}).get(\"git_commits\", [])\n",
    "            ]\n",
    "\n",
    "            existing_edges = set()\n",
    "\n",
    "            for git_commit in git_commits_for_issue:\n",
    "                edge = GitCommitPullRequestEdge(\n",
    "                    git_commit=git_commit,\n",
    "                    pr=pr,\n",
    "                    relation=\"linked_via_issue\"\n",
    "                )\n",
    "                if edge not in existing_edges:\n",
    "                    graph.add_edge(edge)\n",
    "                    counts[\"linked_via_issue\"] += 1\n",
    "                    existing_edges.add(edge)\n",
    "\n",
    "    for key in counts.keys():\n",
    "        print(f\"{key}: {counts[key]}\")\n",
    "\n",
    "def save_pickle(obj, var_name: str, base_dir: str = \"pickle_data\") -> Path:\n",
    "    \"\"\"\n",
    "    Save a Python object using pickle in a directory relative to the notebook.\n",
    "\n",
    "    Args:\n",
    "        obj: The Python object to save.\n",
    "        var_name: Name of the variable (used as filename).\n",
    "        base_dir: Relative directory to save pickles (default: \"pickle_data\").\n",
    "\n",
    "    Returns:\n",
    "        Path to the saved pickle file.\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    save_dir = Path(base_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build full path\n",
    "    pickle_path = save_dir / f\"{var_name}.pkl\"\n",
    "\n",
    "    # Save object\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "    print(f\"Saved {var_name} to {pickle_path}\")\n",
    "    return pickle_path\n",
    "\n",
    "\n",
    "\n",
    "link_issues_with_git_commits(graph)\n",
    "link_pull_request_with_issue(graph)\n",
    "# 8 min 33 sec\n",
    "link_pull_requests_with_git_commits(graph)\n",
    "\n",
    "save_pickle(graph, \"graph\")\n"
   ],
   "id": "80b21a3fd419e3bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3642 Issueâ€“Commit edges\n",
      "Commits liked with issues: 3209\n",
      "Created 4385 PRâ€“Issue edges\n",
      "PRs linked with issues: 3974\n",
      "merged_as: 916\n",
      "linked_via_issue: 11182\n",
      "Saved graph to pickle_data/graph.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('pickle_data/graph.pkl')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Altele",
   "id": "350d307d51eac43c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T23:01:03.497818Z",
     "start_time": "2025-09-07T23:01:03.495603Z"
    }
   },
   "cell_type": "code",
   "source": "print(graph.summary())",
   "id": "b2058c48b82662d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Graph summary ~~~~\n",
      "commits: 5512\n",
      "git_users: 602\n",
      "files: 5644\n",
      "\n",
      "issue_statuses: 48\n",
      "issue_types: 7\n",
      "issue_status_categories: 3\n",
      "jira_users: 2008\n",
      "issues: 6202\n",
      "\n",
      "pull_requests: 5022\n",
      "git_hub_users: 690\n",
      "git_hub_commits: 17869\n",
      "\n",
      "nodes: 43607edges: 175553\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T20:28:32.894489Z",
     "start_time": "2025-09-07T20:28:32.866860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Counter\n",
    "\n",
    "# 1. Find the bug type node (by name)\n",
    "bug_types = [\n",
    "    it for it in graph.issue_types.values()\n",
    "    if it.name == \"Bug\"\n",
    "]\n",
    "\n",
    "# 2. Define traversal steps:\n",
    "#    IssueType â†’ Issues â†’ Commits â†’ Files\n",
    "steps = [\n",
    "    (\"issues\", None),                      # IssueType â†’ Issues\n",
    "    (\"git_commits\", None),                 # Issues â†’ Commits\n",
    "    (\"files\", None),                       # Commits â†’ Files\n",
    "]\n",
    "\n",
    "# 3. Traverse\n",
    "all_files = graph.filtered_traversal(\n",
    "    start_nodes=bug_types,\n",
    "    steps=steps,\n",
    ")\n",
    "\n",
    "# 4. Count by file path\n",
    "file_counter = Counter(f.path for f in all_files)\n",
    "\n",
    "# 5. Show top 5\n",
    "for file, count in file_counter.most_common(5):\n",
    "    print(f\"{file}: seen in {count} bug issues\")"
   ],
   "id": "801455c761dc6004",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dev/null: seen in 111 bug issues\n",
      "zeppelin-server/src/main/java/org/apache/zeppelin/socket/NotebookServer.java: seen in 97 bug issues\n",
      "zeppelin-web/src/app/notebook/paragraph/paragraph.controller.js: seen in 88 bug issues\n",
      "zeppelin-zengine/src/main/java/org/apache/zeppelin/notebook/Note.java: seen in 70 bug issues\n",
      "pom.xml: seen in 66 bug issues\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
